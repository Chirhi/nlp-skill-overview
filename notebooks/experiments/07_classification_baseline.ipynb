{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab33e4b2",
   "metadata": {},
   "source": [
    "Загрузить данные из таблицы test.xlsx.  \n",
    "Проанализировать текст в колонке text, используя метод обработки текста.  \n",
    "Сгенерировать вероятный краткий ответ из всего текста (состоящий из нескольких слов) и записать его в колонку answer.  \n",
    "\n",
    "Пример:  \n",
    "Текст1 - Удовлетворить  \n",
    "Текст2 - Производство окончено  \n",
    "Текст3 - Отказ, ИП приостановлено  \n",
    "Текст4 - Отказ, невозможно установить местонахождение должника  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce50b5",
   "metadata": {},
   "source": [
    "Такую задачу можно просто сделать через LLM, через OpenRouter с бесплатными моделями, но тут будет хромать скорость и лимиты запросов, доступность сервиса. Если же сделать через платный API, то нужны постоянные дополнительные затраты.\n",
    "Так что можно сделать через более простые способы, попробовать линейные модели и бустинг модели, базовые обработки текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488f4ff",
   "metadata": {},
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7416418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb634782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/rule_classified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a19a1",
   "metadata": {},
   "source": [
    "Будем применять линейнеые и бустинг модели: Naive Bayes, Logistic Regression, SVM, Decision Tree, RandomForest, GradientBoosting, HistGradientBoostingClassifier, CatBoost, XGBoost, LightGBM.  \n",
    "Может ещё в конце языковые модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478f6870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer\n",
       "Отказ                                     217\n",
       "Частично удовлетворено                    138\n",
       "Обращение рассмотрено                     130\n",
       "Взыскание обращено                        106\n",
       "Запрос направлен                           80\n",
       "Возбуждено исполнительное производство     76\n",
       "Постановление вынесено                     37\n",
       "Удовлетворено                              27\n",
       "Заявления и жалобы рассматриваются         26\n",
       "Объявлен исполнительный розыск             20\n",
       "Применены меры для исполнения              19\n",
       "Запрет действий                            14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = df[df['answer'].notna()].copy()\n",
    "# original_indices_labeled = df_labeled.index.copy() # Для последующего объеденения с предсказаниями\n",
    "df_labeled = df_labeled.reset_index(drop=True)\n",
    "\n",
    "df_labeled['answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010477c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Размеры классов тренировочной выборки:===============\n",
      "answer\n",
      "Отказ                                     152\n",
      "Частично удовлетворено                     97\n",
      "Обращение рассмотрено                      91\n",
      "Взыскание обращено                         74\n",
      "Запрос направлен                           56\n",
      "Возбуждено исполнительное производство     53\n",
      "Постановление вынесено                     26\n",
      "Удовлетворено                              19\n",
      "Заявления и жалобы рассматриваются         18\n",
      "Объявлен исполнительный розыск             14\n",
      "Применены меры для исполнения              13\n",
      "Запрет действий                            10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "===============Размеры классов тестовой выборки:===============\n",
      "answer\n",
      "Отказ                                     65\n",
      "Частично удовлетворено                    41\n",
      "Обращение рассмотрено                     39\n",
      "Взыскание обращено                        32\n",
      "Запрос направлен                          24\n",
      "Возбуждено исполнительное производство    23\n",
      "Постановление вынесено                    11\n",
      "Заявления и жалобы рассматриваются         8\n",
      "Удовлетворено                              8\n",
      "Объявлен исполнительный розыск             6\n",
      "Применены меры для исполнения              6\n",
      "Запрет действий                            4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.classification_utils import split_data, encode_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_labeled)\n",
    "y_train_enc, y_test_enc, le = encode_labels(y_train, y_test)\n",
    "\n",
    "print(f\"{'='*15}Размеры классов тренировочной выборки:{'='*15}\\n{y_train.value_counts()}\\n\")\n",
    "print(f\"{'='*15}Размеры классов тестовой выборки:{'='*15}\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c2f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.classifiers import get_classifiers\n",
    "\n",
    "# Получаем список векторизированных данных\n",
    "with open('vectors/vectorizers.pkl', 'rb') as f:\n",
    "    vectorizers = pickle.load(f)\n",
    "\n",
    "# Получаем список моделей и параметры их обучения\n",
    "classifiers = get_classifiers(le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbcfa1",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ed2f4",
   "metadata": {},
   "source": [
    "Попробуем линейные модели, если они будут плохи, откинем их.  \n",
    "Скорее всего бустинг модели будут хороши в этой задаче, а может и слишком сложны.  \n",
    "Разница между ними под капотом большая, но можно попробовать все, сравнить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbaf077",
   "metadata": {},
   "source": [
    "Обучим алгоритмы на тех данных, которые уже имеют верные метки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73252098",
   "metadata": {},
   "source": [
    "Может стоит попробывать соединить tf-idf с word2vec, потому-что часто попадаются по всему датасету шаблонные фразы, а word2vec может уловить семантическую близость между разными формулировками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5bb71",
   "metadata": {},
   "source": [
    "#### Без MLFlow, старый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b563edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script cmd /c \"\"\n",
    "# Оставил вариант без mlflow, который я делал как первый тест моделей\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# При обучении выдаёт разные warning, можно игнорировать, так как не мешают. Может быть из-за попытки сделать часть моделей на гпу\n",
    "# - UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Исправляется через SMOTE из-за редкости классов\n",
    "# - DataConversionWarning: A column-vector y was passed when a 1d array was expected. Точно подаётся одномерный массив, но всё равно предупреждение\n",
    "# - UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names. Подаётся np.array, но всё равно предупреждение\n",
    "\n",
    "for vec_name, (train_path, test_path) in vectorizers.items():\n",
    "    print(f\"\\n{'|'*50}{vec_name}{'|'*50}\\n\")\n",
    "\n",
    "    # Загружаем только для текущей итерации, памяти ради\n",
    "    if train_path.endswith('.npz'):\n",
    "        from scipy.sparse import load_npz\n",
    "        X_train_vec = load_npz(train_path)\n",
    "        X_test_vec = load_npz(test_path)\n",
    "    else: # .npy\n",
    "        X_train_vec = np.load(train_path)\n",
    "        X_test_vec = np.load(test_path)\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        print(f\"\\n{'='*90}\\nМодель: {name} \\n{'='*90}\\n\") \n",
    "        \n",
    "        classifier.fit(X_train_vec, y_train_enc)\n",
    "        y_pred = classifier.predict(X_test_vec)\n",
    "        y_pred_labels = le.inverse_transform(y_pred)\n",
    "        print(classification_report(y_test, y_pred_labels, digits=3))\n",
    "\n",
    "    # Освобождаем память\n",
    "    del X_train_vec, X_test_vec\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a669852",
   "metadata": {},
   "source": [
    "`UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use zero_division parameter to control this behavior. _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])`\n",
    "\n",
    "Ошибка возникает, так как модели не предсказывают ни одного примера редких классов, более сложные модели же попытались, хоть и не очень удачно по precision, recall, f1, но немного лучше чем просто угадывание по всем классам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c7c1f",
   "metadata": {},
   "source": [
    "#### С MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fc800",
   "metadata": {},
   "source": [
    "Для запуска MLFlow ввести в cmd:\n",
    "```python\n",
    "mlflow server `\n",
    "  --backend-store-uri sqlite:///mlruns/mlflow.db `\n",
    "  --default-artifact-root ./mlruns/artifacts `\n",
    "  --host 127.0.0.1 `\n",
    "  --port 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4a8e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940af781788a49aca6eee9c2ef62fe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Векторизаторы:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c7c54a9807423eb5035d8636d57452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Классификаторы:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.classification_utils import load_np_arrays, crossval_report, log_report\n",
    "import mlflow\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "os.environ['MLFLOW_SUPPRESS_PRINTING_URL_TO_STDOUT'] = '1' # так как выводит view run и view experiment из-за того, что запустил отдельный сервер\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment('text_classification')\n",
    "\n",
    "pbar_vectorizers = tqdm(total=len(vectorizers), desc='Векторизаторы', position=0)\n",
    "pbar_classifiers = tqdm(total=len(classifiers), desc='Классификаторы', position=1)\n",
    "\n",
    "for vec_name, (train_path, test_path) in vectorizers.items(): # items так как словарь\n",
    "    X_train_vec, X_test_vec = load_np_arrays(train_path, test_path)\n",
    "\n",
    "    pbar_vectorizers.set_description(f'Векторизатор: {vec_name}')\n",
    "    pbar_classifiers.reset()\n",
    "    \n",
    "    for classifier_name, classifier in classifiers:\n",
    "        pipeline = classifier\n",
    "        report = crossval_report(classifier, X_train_vec, y_train, y_train_enc, le, pipeline=pipeline)\n",
    "        log_report(report, vec_name, classifier_name, resampler_name='no_resampler')\n",
    "\n",
    "        pbar_classifiers.set_description(f'Классификатор: {classifier_name}')\n",
    "        pbar_classifiers.update(1)\n",
    "\n",
    "    pbar_vectorizers.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637a943",
   "metadata": {},
   "source": [
    "Новые метрики уже больше похожи на правду, почти нету метрик с идеальным показателем 1.0.  \n",
    "Также линейные модели лучше предсказывают самый редкий класс, чем бустинговые модели, кроме Gradient Boosting. Это может быть, потому-что бустинг модели пытаются уменьшить ошибку на всех классах, пренебрегая самым редким классом спустя множество бустинг моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cc126",
   "metadata": {},
   "source": [
    "- Можно попробовать увеличить размер минорного (миноритарного) класса через его дублирование (RandomOverSampler)(более простой) или через SMOTE.  \n",
    "- Также можно попробовать изменить вес класса вручную для каждой модели, чем и можно заняться перед SMOTE.  \n",
    "- Focal Loss для поддерживаемых моделей.\n",
    "- Сравнить TF-IDF с Word2Vec, GloVe, FastText.\n",
    "- Попровать сделать что-то с ruBERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff44d1",
   "metadata": {},
   "source": [
    "Думал аугментировать данные, но замена синонимами, перефразированием в таком датасете может не представлять сам датасет, так как фразы шаблонны.  \n",
    "Можно сделать синтетические примеры через LLM, но это напоследок, если всё будет плохо с малыми классами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ba787",
   "metadata": {},
   "source": [
    "### Классификация неразмеченного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196228a",
   "metadata": {},
   "source": [
    "#### Через ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34720ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df[df['answer'].isna()].copy()\n",
    "# original_indices_unlabeled = df_labeled.index.copy()\n",
    "df_unlabeled = df_unlabeled.reset_index(drop=True) # Нужно обнулить индексы, так как предсказывает только 100 из 322 почему-то\n",
    "X_unlabeled = df_unlabeled['lemmatized_text']\n",
    "\n",
    "predictions_all = {}\n",
    "for name, pipeline in trained_pipelines.items():\n",
    "    preds = pipeline.predict(X_unlabeled)\n",
    "    predictions_all[name] = preds.ravel() if hasattr(preds, \"ravel\") else preds # ravel() так как CatBoost выдаёт двумерный массив, вместо одномерного\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_all)\n",
    "# # Перевернуть столбцы, чтобы из-за mode, которая при всех разных вариантов выбирает первый столбце в списке, выбиралась лучшая модель - SVM\n",
    "# predictions_df = predictions_df[['SVM', 'Logistic Regression', 'Naive Bayes']]\n",
    "\n",
    "# Преобразуем обратно в текстовые метки\n",
    "for col in predictions_df.columns:\n",
    "    predictions_df[col] = le.inverse_transform(predictions_df[col])\n",
    "\n",
    "# Выбрать наиболее частый ответ среди всех строк\n",
    "df_unlabeled['answer'] = predictions_df.mode(axis=1)[0]\n",
    "\n",
    "\n",
    "print(\"Датафрейм с предсказаниями от всех моделей:\")\n",
    "print(predictions_df.head())\n",
    "\n",
    "print(\"\\nКоличество предсказанных классов:\", df_unlabeled['answer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be404646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled[['answer', 'lemmatized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01b351",
   "metadata": {},
   "source": [
    "То есть любые неизвестные текста модели относят к \"Обращение рассмотрено\", что говорит о том, что классов недостаточно и нужно придумывать что-то иное, но, по-крайне мере модели предсказывают классы с высокими метриками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552221e",
   "metadata": {},
   "source": [
    "#### Итоговый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef826b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.index = df[df['answer'].notna()].index\n",
    "df_unlabeled.index = df[df['answer'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([df_labeled, df_unlabeled]).sort_index()\n",
    "\n",
    "print(df.index)\n",
    "print(df_result.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9714335",
   "metadata": {},
   "source": [
    "Индексы ~совпадают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86172a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраню в xlsx, так как много строк имеют \\n и \\r символов, что ломает разделение строк в csv\n",
    "df_result[['Id', 'text', 'answer']].to_excel('data/processed/result.xlsx', index=False)\n",
    "df_result.to_excel('data/processed/result_detailed.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
