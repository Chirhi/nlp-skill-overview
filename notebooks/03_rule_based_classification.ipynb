{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aed0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9987b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a61257",
   "metadata": {},
   "source": [
    "### Rule-based метод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330de760",
   "metadata": {},
   "source": [
    "Так как в тексте могут быть явные указатели, при этом ответ почти всегда следует одному шаблону, запишем в answer уже явные ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3eb8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Функции чтобы искать именно слова, а не подстроки\n",
    "# Хотя бы одно слово\n",
    "def has_any_words(words, text):\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(word) for word in words) + r')\\b'\n",
    "    return bool(re.search(pattern, text, flags=re.IGNORECASE))\n",
    "\n",
    "# Хотя бы все слова\n",
    "def has_all_words(words, text):\n",
    "    for word in words:\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        if not re.search(pattern, text, flags=re.IGNORECASE):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Тут я пытался сделать через список, функции, сочетание с lambda этих способов, \n",
    "# но ничего не работало из-за логики определения удовлетворено/частично удовлетворено/отказ и без вложенных if elif это не сделать\n",
    "# Пока что это тяжело читать и расширять, но это делается легко и быстро. То есть это не в моего опыта сделать это лучше\n",
    "def extract_status(text):\n",
    "    if has_all_words(['подлежащее удовлетворение'], text):\n",
    "        if has_any_words(['не_подлежащее', 'не_удовлетворение'], text):\n",
    "            return 'Частично удовлетворено'\n",
    "        return 'Удовлетворено'\n",
    "    elif has_any_words(['не_подлежащее', 'не_удовлетворение'], text):\n",
    "        if has_all_words(['подлежащее', 'удовлетворение'], text):\n",
    "            return 'Частично удовлетворено'\n",
    "        return 'Отказ'\n",
    "    elif has_all_words(['обратить', 'взыскание'], text) or has_all_words(['обращение', 'взыскание',], text) and not has_all_words(['не_иметься'], text):\n",
    "        return 'Взыскание обращено'\n",
    "    elif has_any_words(['действие', 'рег', 'регистрационный'], text) and has_all_words(['запрет'], text):\n",
    "        return 'Запрет действий'\n",
    "    elif has_all_words(['невозможно', 'установить'], text) or has_all_words(['не_представиться', 'лицо'], text) or has_all_words(['не_установить', 'должник'], text):\n",
    "        return 'Невозможно установить местонахождение должника' # всего 10 примеров, всё портит при проверке, даже через Strat K-Fold и SMOTE\n",
    "    # elif has_all_words(['окончить', 'производство'], text): # слишком малый класс - 5 примеров\n",
    "    #     return 'Производство окончено'\n",
    "    elif has_all_words(['вынести', 'постановление'], text):\n",
    "        return 'Постановление вынесено'\n",
    "    elif has_all_words(['направить', 'запрос'], text):\n",
    "        return 'Запрос направлен'\n",
    "    elif has_all_words(['обращение', 'рассмотреть'], text) or has_all_words(['обращение', 'ответ'], text):\n",
    "        return 'Обращение рассмотрено'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9254b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "Отказ                                             195\n",
      "Частично удовлетворено                            116\n",
      "Взыскание обращено                                108\n",
      "Обращение рассмотрено                             100\n",
      "Запрос направлен                                   78\n",
      "Постановление вынесено                             36\n",
      "Удовлетворено                                      27\n",
      "Запрет действий                                    14\n",
      "Невозможно установить местонахождение должника     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Всего обработано строк: 684\n"
     ]
    }
   ],
   "source": [
    "df['answer'] = df['lemmatized_text'].apply(extract_status)\n",
    "\n",
    "print(df['answer'].value_counts())\n",
    "print(\"\\nВсего обработано строк:\", df['answer'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c5643",
   "metadata": {},
   "source": [
    "Cтоит убрать классы меньше чем с 10 примерами, так как они позже будут мешать обучению модели.  \n",
    "Если же переименовать такие классы на просто \"другие\", то модель может классифицировать многие тексты, как \"другие\", что не очень то является ответом на заявление"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e5a283",
   "metadata": {},
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563b3cb",
   "metadata": {},
   "source": [
    "Таким образом осталось ~треть данных из 1000 строк  \n",
    "Остались только не входящие в правила строки и, возможно, неправильно обработанные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f6364",
   "metadata": {},
   "source": [
    "Пока разметка классов идёт по первым встреченным словам.  \n",
    "Проблема в том, что одна строка может иметь много классов, что переходит в многолейбловую классификацию, что не оставляет самые распространённые методы по типу SVM, Log Reg, K-means, а требует что-то похожее на MultiOutputClassifier.  \n",
    "Также среди размеченных данных могут быть такие классы, которые встречаются только в числе других классов, а не одиночно, что значит не хватает размера датасета и модель просто не сможет правильно классифицировать.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05df771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/processed/rule_classified.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
