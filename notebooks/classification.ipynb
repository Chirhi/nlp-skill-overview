{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab33e4b2",
   "metadata": {},
   "source": [
    "Загрузить данные из таблицы test.xlsx.  \n",
    "Проанализировать текст в колонке text, используя метод обработки текста.  \n",
    "Сгенерировать вероятный краткий ответ из всего текста (состоящий из нескольких слов) и записать его в колонку answer.  \n",
    "\n",
    "Пример:  \n",
    "Текст1 - Удовлетворить  \n",
    "Текст2 - Производство окончено  \n",
    "Текст3 - Отказ, ИП приостановлено  \n",
    "Текст4 - Отказ, невозможно установить местонахождение должника  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce50b5",
   "metadata": {},
   "source": [
    "Такую задачу можно просто сделать через LLM, через OpenRouter с бесплатными моделями, но тут будет хромать скорость и лимиты запросов, доступность сервиса. Если же сделать через платный API, то нужны постоянные дополнительные затраты.\n",
    "Так что можно сделать через более простые способы, попробовать линейные модели и бустинг модели, базовые обработки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7416418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb634782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/rule_classified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f5f52",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8977b2",
   "metadata": {},
   "source": [
    "### Naive Bayes, Logistic Regression, SVM, RandomForest, GradientBoosting, CatBoost, XGBoost, LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ed2f4",
   "metadata": {},
   "source": [
    "Попробуем линейные модели, если они будут плохи, откинем их.  \n",
    "Скорее всего бустинг модели будут хороши в этой задаче, а может и слишком сложны.  \n",
    "Разница между ними под капотом большая, но можно попробовать все, сравнить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbaf077",
   "metadata": {},
   "source": [
    "Обучим алгоритмы на тех данных, которые уже имеют верные метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478f6870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer\n",
       "Отказ                                             195\n",
       "Частично удовлетворено                            116\n",
       "Взыскание обращено                                108\n",
       "Обращение рассмотрено                             100\n",
       "Запрос направлен                                   78\n",
       "Постановление вынесено                             36\n",
       "Удовлетворено                                      27\n",
       "Запрет действий                                    14\n",
       "Невозможно установить местонахождение должника     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = df[df['answer'].notna()].copy()\n",
    "# original_indices_labeled = df_labeled.index.copy() # Для последующего объеденения с предсказаниями\n",
    "df_labeled = df_labeled.reset_index(drop=True)\n",
    "\n",
    "df_labeled['answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010477c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 # Чтобы если что надо поменять в функциях в .py\n",
    "\n",
    "from src.classification_utils import split_data, encode_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_labeled)\n",
    "y_train_enc, y_test_enc, le = encode_labels(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classifiers = [\n",
    "    # ('Naive Bayes', MultinomialNB()), # требует только bag-of-words или tf-idf. Имеет худший результат. Можно сразу исключить.\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, \n",
    "                                               random_state=1, \n",
    "                                               class_weight='balanced')), # балансируем, так как слишком редкие классы\n",
    "    ('SVM', LinearSVC(max_iter=2000, \n",
    "                      random_state=1, \n",
    "                      class_weight='balanced')),\n",
    "    ('Decision Tree', DecisionTreeClassifier(max_depth=6,\n",
    "                                             random_state=1,\n",
    "                                             class_weight='balanced')),\n",
    "    ('Random Forest', RandomForestClassifier(max_depth=6, # попытался ограничить глубину деревьев, так как кажется слишком сложные модели для такой задачи и идёт переобучение\n",
    "                                             random_state=1,\n",
    "                                             class_weight='balanced')),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=1)),\n",
    "    ('CatBoost', CatBoostClassifier(verbose=0,\n",
    "                                    random_state=1,\n",
    "                                    n_estimators=100,\n",
    "                                    max_depth=6,\n",
    "                                    loss_function='MultiClass',\n",
    "                                    auto_class_weights='Balanced',\n",
    "                                    train_dir=None)), # всё равно сохраняет папку\n",
    "    ('XGBoost', XGBClassifier(objective='multi:softmax', \n",
    "                              random_state=1, \n",
    "                              n_estimators=100,\n",
    "                              learning_rate=0.1,\n",
    "                              max_depth=6,\n",
    "                              num_class=len(le.classes_))),\n",
    "    ('LightGBM', LGBMClassifier(objective='multiclass',\n",
    "                                n_estimators=100,\n",
    "                                max_depth=6,\n",
    "                                num_class=len(le.classes_),\n",
    "                                class_weight='balanced',\n",
    "                                random_state=1,\n",
    "                                verbosity=-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Создаем pipeline для каждой модели\n",
    "for name, classifier in classifiers:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000, # Пока пробуем tf-idf\n",
    "                                ngram_range=(1, 2))),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train_enc)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a669852",
   "metadata": {},
   "source": [
    "`UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use zero_division parameter to control this behavior. _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])`\n",
    "\n",
    "Ошибка возникает, так как модель Naive Bayes не предсказал ни одного примера редких классов, SVM и Log Reg же попытались, хоть и не очень удачно по precision, recall, f1, но немного лучше чем просто угадывание по всем классам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f4d10",
   "metadata": {},
   "source": [
    "SVM и Log Reg имеют лучшие показатели точности accuracy, но в этом случае это не показывает качество модели из-за несбалансированных классов.\n",
    "NB имеет худшие результаты, он не определяет самые редкие классы, впрочем SVM и Log Reg методы так же имеют плохие f1 score на тех же классах, хоть и показывают хорошие macro avg (метрика, которая вместе с несбалансированными классами больше показывает модель) и weighted avg.  \n",
    "\n",
    "Модели Random Forest, Gradient Boosting, CatBoost, XGBoost и LightGBM уже имеют намного лучшие результаты, но, кажется, есть переобучение, особенно LightGBM, так как почти все метрики 1.0 по F1, даже на редких классах. Попробовал ограничить глубину."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57122759",
   "metadata": {},
   "source": [
    "### Вместе с Strat K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3241354",
   "metadata": {},
   "source": [
    "#### Попытка 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9182467",
   "metadata": {},
   "source": [
    "Попробуем проверить через K-Fold, но с Stratified, чтобы учесть несбалансированность классов и понять какие модели не нестабильны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077923ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Создаем pipeline для каждой модели\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000,\n",
    "                                ngram_range=(1, 2))),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Кросс-валидация\n",
    "    y_pred_cv = cross_val_predict(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train_enc,\n",
    "        cv=skf,\n",
    "        method='predict'\n",
    "    )\n",
    "\n",
    "    y_pred_cv_labels = le.inverse_transform(y_pred_cv)\n",
    "    y_train_labels = le.inverse_transform(y_train_enc)\n",
    "    \n",
    "    print(classification_report(y_train_labels, y_pred_cv_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637a943",
   "metadata": {},
   "source": [
    "Новые метрики уже больше похожи на правду, почти нету метрик с идеальным показателем 1.0.  \n",
    "Также линейные модели лучше предсказывают самый редкий класс, чем бустинговые модели, кроме Gradient Boosting. Это может быть, потому-что бустинг модели пытаются уменьшить ошибку на всех классах, пренебрегая самым редким классом спустя множество бустинг моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363424d",
   "metadata": {},
   "source": [
    "#### Попытка 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cc126",
   "metadata": {},
   "source": [
    "- Можно попробовать увеличить размер минорного (миноритарного) класса через его дублирование (RandomOverSampler)(более простой) или через SMOTE.  \n",
    "- Также можно попробовать изменить вес класса вручную для каждой модели, чем и можно заняться перед SMOTE.  \n",
    "- Focal Loss для поддерживаемых моделей.\n",
    "- Сравнить TF-IDF с Word2Vec, GloVe, FastText.\n",
    "- Попровать сделать что-то с ruBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd42ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Создаем pipeline для каждой модели\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000,\n",
    "                                ngram_range=(1, 2))),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Кросс-валидация\n",
    "    y_pred_cv = cross_val_predict(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train_enc,\n",
    "        cv=skf,\n",
    "        method='predict'\n",
    "    )\n",
    "\n",
    "    y_pred_cv_labels = le.inverse_transform(y_pred_cv)\n",
    "    y_train_labels = le.inverse_transform(y_train_enc)\n",
    "    \n",
    "    print(classification_report(y_train_labels, y_pred_cv_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8373f",
   "metadata": {},
   "source": [
    "### Вместе с SMOTE и Strat K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1412356",
   "metadata": {},
   "source": [
    "K-Fold показал, что всё таки требуется SMOTE, так как некоторые метрики не сильно растут, а другие снижаются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff44d1",
   "metadata": {},
   "source": [
    "Думал аугментировать данные, но замена синонимами, перефразированием в таком датасете может не представлять сам датасет, так как фразы шаблонны.  \n",
    "Можно сделать синтетические примеры через LLM, но это напоследок, если всё будет плохо с малыми классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75111e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим сколько будет пример до и после\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "smote = SMOTE(random_state=1, sampling_strategy='not majority')\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Размер классов train до:\", y_train.value_counts())\n",
    "print(\"\\nРазмер классов train после:\", y_train_balanced.value_counts())\n",
    "\n",
    "print(\"\\nРазмер train до:\", len(y_train))\n",
    "print(\"Размер train после:\", len(y_train_balanced))\n",
    "print(\"Добавлено всего:\", len(y_train_balanced) - len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    pipeline = ImbPipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000,\n",
    "                                ngram_range=(1, 2))),\n",
    "        ('smote', SMOTE(\n",
    "            random_state=1,\n",
    "            sampling_strategy='not majority',\n",
    "            k_neighbors=4\n",
    "        )),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    y_pred_cv = cross_val_predict(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train_enc,\n",
    "        cv=skf,\n",
    "        method='predict'\n",
    "    )\n",
    "    \n",
    "    y_pred_cv_labels = le.inverse_transform(y_pred_cv)\n",
    "    y_true_labels = le.inverse_transform(y_train_enc)\n",
    "    \n",
    "    print(classification_report(y_true_labels, y_pred_cv_labels, digits=3))\n",
    "\n",
    "    # y_pred = pipeline.predict(X_test)\n",
    "    # y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "    # print(classification_report(y_test, y_pred_labels))\n",
    "\n",
    "    # trained_pipelines[name] = pipeline\n",
    "\n",
    "\n",
    "    # with open(f'pipeline_{name}.pkl', 'wb') as f:\n",
    "    #     pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7865f8",
   "metadata": {},
   "source": [
    "SMOTE помог только Naive Bayes методу предсказать ранее не предсказанные классы, и повысить все метрики.  \n",
    "Метрики же на других методах не сильно поменялись или вообще стали чуть хуже. На более сложных же моделях метрики стали намного лучше "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8067ce6",
   "metadata": {},
   "source": [
    "В итоге лучшими моделями оказались Gradient Boosting, XGBoost и LightGBM.  \n",
    "Можно сделать ансамбль из этих моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f990361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df_labeled['lemmatized_text']\n",
    "y = df_labeled['answer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=1,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_model_names = ['Gradient Boosting', 'XGBoost', 'LightGBM']\n",
    "best_classifiers = [pair for pair in classifiers if pair[0] in best_model_names]\n",
    "\n",
    "trained_pipelines = {}\n",
    "\n",
    "for name, classifier in best_classifiers:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "\n",
    "    pipeline = ImbPipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000,\n",
    "                                ngram_range=(1, 2))),\n",
    "        ('smote', SMOTE(\n",
    "            random_state=1,\n",
    "            sampling_strategy='not majority'\n",
    "        )),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train_enc)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "    print(classification_report(y_test, y_pred_labels, digits=3))\n",
    "\n",
    "    trained_pipelines[name] = pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4429d57",
   "metadata": {},
   "source": [
    "~~Так как метрики относительно одинаковы между Log Reg и SVM, можно выбрать одну из них. Однако Naive Bayes выдаёт иные метрики, некоторые лучше, в основном хуже. Можно попробовать ансамбль моделей~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ba787",
   "metadata": {},
   "source": [
    "### Классификация неразмеченного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196228a",
   "metadata": {},
   "source": [
    "#### Через ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34720ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df[df['answer'].isna()].copy()\n",
    "# original_indices_unlabeled = df_labeled.index.copy()\n",
    "df_unlabeled = df_unlabeled.reset_index(drop=True) # Нужно обнулить индексы, так как предсказывает только 100 из 322 почему-то\n",
    "X_unlabeled = df_unlabeled['lemmatized_text']\n",
    "\n",
    "predictions_all = {}\n",
    "for name, pipeline in trained_pipelines.items():\n",
    "    preds = pipeline.predict(X_unlabeled)\n",
    "    predictions_all[name] = preds.ravel() if hasattr(preds, \"ravel\") else preds # ravel() так как CatBoost выдаёт двумерный массив, вместо одномерного\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_all)\n",
    "# # Перевернуть столбцы, чтобы из-за mode, которая при всех разных вариантов выбирает первый столбце в списке, выбиралась лучшая модель - SVM\n",
    "# predictions_df = predictions_df[['SVM', 'Logistic Regression', 'Naive Bayes']]\n",
    "\n",
    "# Преобразуем обратно в текстовые метки\n",
    "for col in predictions_df.columns:\n",
    "    predictions_df[col] = le.inverse_transform(predictions_df[col])\n",
    "\n",
    "# Выбрать наиболее частый ответ среди всех строк\n",
    "df_unlabeled['answer'] = predictions_df.mode(axis=1)[0]\n",
    "\n",
    "\n",
    "print(\"Датафрейм с предсказаниями от всех моделей:\")\n",
    "print(predictions_df.head())\n",
    "\n",
    "print(\"\\nКоличество предсказанных классов:\", df_unlabeled['answer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be404646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled[['answer', 'lemmatized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01b351",
   "metadata": {},
   "source": [
    "То есть любые неизвестные текста модели относят к \"Обращение рассмотрено\", что говорит о том, что классов недостаточно и нужно придумывать что-то иное, но, по-крайне мере модели предсказывают классы с высокими метриками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552221e",
   "metadata": {},
   "source": [
    "#### Итоговый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef826b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.index = df[df['answer'].notna()].index\n",
    "df_unlabeled.index = df[df['answer'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([df_labeled, df_unlabeled]).sort_index()\n",
    "\n",
    "print(df.index)\n",
    "print(df_result.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9714335",
   "metadata": {},
   "source": [
    "Индексы ~совпадают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86172a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраню в xlsx, так как много строк имеют \\n и \\r символов, что ломает разделение строк в csv\n",
    "df_result[['Id', 'text', 'answer']].to_excel('data/processed/result.xlsx', index=False)\n",
    "df_result.to_excel('data/processed/result_detailed.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e54f3d",
   "metadata": {},
   "source": [
    "## Label Propagation (не стал делать, так как того, что сверху хватило)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
