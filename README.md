Только ipynb файл. Проверка знаний nlp на тестовом датасете по судебным делам.

Задание:
Загрузить данные из таблицы test.xlsx.  
Проанализировать текст в колонке text, используя метод обработки текста.  
Сгенерировать вероятный краткий ответ из всего текста (состоящий из нескольких слов) и записать его в колонку answer.  

Пример:
Текст1 - Удовлетворить
Текст2 - Производство окончено
Текст3 - Отказ
Текст4 - Невозможно установить местонахождение должника

Такую задачу можно просто сделать через LLM, через OpenRouter с бесплатными моделями, но тут будет хромать скорость и лимиты запросов, доступность сервиса. Если же сделать через платный API, то нужны постоянные дополнительные затраты.
Так что попробовал сделал через более простые способы, стандартные методы обработки текста, линейные и бустинг модели.

- Применил разные методы обработки сырых текстовых данных: стоп-слова, орфография, лемматизация
- Опробовал выделение клювыех слов через RAKE, YAKE (неудачно из-за состава текста в датасете)
- Сделал первичную классификацию для подачи на модели с помощью обычных правил на ключевые лемматизированные слова
- Сделал SMOTE
- Обучил модели Naive Bayes, Logistic Regression, SVM, Random Forest, CatBoost, XGBoost, Gradient Boosting
- Проверил устойчивость моделей через Stratified K-Fold
- Сделал ансамбль вероятных ответов самых лучших моделей на эти текста по типу "удовлетворено, отказ, запрет действий и т.д."

- Получил результат:
  - Macro F1 = ~0.955
  - Macro Precision = 0.975
  - Macro Recall = 0.945
  - Avg Accuracy ~0.97

Структура:
цифра_...ipynb - порядок обработки и экспериментов

01_preprocessing.ipynb - обработка текста и подготовка данных к модели
02_keyword_extraction.ipynb - эксперимент с моделями RAKE и YAKE
03_rule_based_classification.ipynb - первичная классификация с помощью обычных правил на лемматизированные текста
